{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TE_myjakNHU"
   },
   "source": [
    "# Tutorial 5: Reliability and Validity of Questionnaires\n",
    "**Date**: March 2022\n",
    "\n",
    "**Background**\n",
    "\n",
    "In the last tutorial, you learned how to clean the survey data. You went through the steps to import survey data into pandas, analyze the datatypes, transform the data for quantitative processing and handle missing values. The last tutorial also gave us practice in using python functions - `dtypes()` to check variables' type, `value_counts()` to explore percentages in tolerance questions and `fillna()` to handle missing data.\n",
    "\n",
    "\n",
    "In today's tutorial, you will **assess the reliability and validity of questionnaires**. We will focus on the same case-study from the last tutorial to measure tolerance. \n",
    "\n",
    "**Goal of the Case-Study**\n",
    "\n",
    "The goal of this case-study is to examine the attitude of 150 students towards tolerance where tolerance refers to the degree of diversity. The researchers developed a questionnaire focusing on the **three different expressions/constructs of tolerance** based on [1] theoretical framework:\n",
    "\n",
    "\n",
    "<p align=\\\"center\\\"><img src='./images/items.png' width=\"1000\" /></p>\n",
    "\n",
    "\n",
    "**Dataset**\n",
    "\n",
    "For this tutorial, we will be using the \"tolerance survey dataset\" from the previous tutorial. \n",
    "\n",
    "The dataset is available here: https://raw.githubusercontent.com/MaastrichtU-IDS/global-studies/main/semester4/tutorial4/inputs/tolerance_survey_data.csv \n",
    "\n",
    "After removing other variables, this dataset has 8 variables (items or questions) that the researchers used to measure tolerance. Each of the 8 variables was assigned to one of the 3 expressions/constructs of tolerance as hypothesized by the researchers: \"**1-Acceptance**\" \"**2-Respect**\" and \"**3-Appreciation**\" towards **diversity**. To measure this construct, several Likert-Type items were added onto the questionnarie. So we're working with 8 variables which are displayed in Table 1:\n",
    "\n",
    "\n",
    "**Table 1**. Survey items and the corresponding expression of tolerance hypothesized by the researchers\n",
    "\n",
    "|Expression of tolerance|variable   |description                                                                                                                                    |\n",
    "|------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "|1- Acceptance     |q1         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [People should have the right to live how they wish]|\n",
    "|1-Acceptance    |q2         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [It is important that people have the freedom to live their life as they choose]     |\n",
    "|1- Acceptance   |q3         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [ It is okay for people to live as they wish as long as they do not harm other people]                                    |\n",
    "|2- Respect    |q4         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [I respect other people’s beliefs and opinions]        |\n",
    "|2- Respect    |q5         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [I respect other people’s opinions even when I do not agree]   |\n",
    "|3-Appreciation  |q6         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [I like to spend time with people who are different from me]                                         |\n",
    "|3-Appreciation    |q7         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [I like people who challenge me to think about the world in a different way]                            |\n",
    "|3-Appreciation   |q8         |five-point Likert Scale from 'strongly disagree' to 'strongly agree': [Society benefits from a diversity of traditions and lifestyles]                            |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Today's Objectives**\n",
    "\n",
    "In today's tutorial, you will **assess the reliability and validity of questionnaires**.\n",
    "\n",
    "In the subsequent exercises we will primarily focus on the following:\n",
    "\n",
    " - exploring the relationship between variables by computing and visualizing the pearson correlation matrix. \n",
    " - assessing the validity of questionnaire by using pearson correlation test\n",
    " - using Cronbach's Alpha to estimate the internal consistency or reliability of the variables that make up the tolerance measure based on the three composite measures. \n",
    "\n",
    "The **main intended learning outcomes (ILOs) of this tutorial are**:\n",
    "\n",
    " - **Measure and interpret the internal consistency of a survey or questionnaire**\n",
    " - **Understand the fundamentals of pearson correlation coefficient to identify opportunities to combine variables**\n",
    "\n",
    "\n",
    "---\n",
    "[1] Hjerm, M., Eger, M. A., Bohman, A., & Fors Connolly, F. (2020). A new approach to the study of tolerance: Conceptualizing and measuring acceptance, respect, and appreciation of difference. Social Indicators Research, 147(3), 897-919.\n",
    "Chicago\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7H9WM9XBFCM"
   },
   "source": [
    "## 1. Setup Library\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries you will need to perform such analysis on the survey data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ye2-0R0IbP-a"
   },
   "source": [
    "## 2. Import and prepare the Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the \"tolerance survey dataset\" from the previous tutorial. For sake of simplicity, please run the following python code that transform the row data into todays data version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data into the dataframe and print the first 10 rows\n",
    "url = 'https://raw.githubusercontent.com/MaastrichtU-IDS/global-studies/main/semester4/tutorial4/inputs/tolerance_survey_data.csv'\n",
    "df = pd.read_csv(url)\n",
    "# transform/prepare the data\n",
    "df_transformed = df.replace(['Strongly Agree',\n",
    "                   'Agree', \n",
    "                   'Neutral', \n",
    "                   'Disagree', \n",
    "                   'Strongly Disagree'], [5,4,3,2,1])\n",
    "\n",
    "df_transformed = df_transformed.drop(['id','age','height','country','language','freq_travel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the df_transformed type of each variable and shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Handling missing values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous tutorial, we found missing values (NaN). Now we need to replace the missing value (NaN) with the mean of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the means of each colum \n",
    "#Hint use the mean() funtion on the dataframe\n",
    "#Use the fillna() function to replace the missing (NaN) value with the mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "## Assessment of Questionnaire's Validity & Reliability\n",
    "\n",
    "After establishing the questionnarie's theoretical construct based on [1] as indicated in Table 1, we need to assess the validity and reliability of the questionnaire. Put simply, we want to address the following question:\n",
    "   > **_Are the items consistent in the sense that each one measures what it intends to measure?_**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validity test with correlation analysis\n",
    "\n",
    "In order to assess construct validity, Pearson's correlation is utilized. Pearson's correlation is commonly used to verify the intensity of the existing linear association between variables. This coefficient is a number between −1 and 1 that expresses the degree of linear dependence between two quantitative variables. \n",
    "If negative, it indicates that one variable decreases as the other increases; if positive, it indicates that one variable increases as the other increases. \n",
    "\n",
    "We want to produce some correlations, as this will give an\n",
    "indication of whether the items are related to the same underlying concept.\n",
    "\n",
    "If all of the items are measuring the same concept, we would expect them all to correlate well together. Any items that have consistently low correlations across the board may need to be removed from the dataframe to make it more valid.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson's Correlation Test with Python**\n",
    "\n",
    "See [previous material](https://github.com/MaastrichtU-IDS/global-studies/blob/main/semester2/notebooks/3.2-NHST-advanced-with-python-solutions.ipynb) from last year about Pearson's correlation test, and how to perform using python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the correlations between the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice: What does this matrix tell you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a heatmap with all correlations using seaborn package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice: Based on the above statistics, can you see a pattern ? Can you group the highly correlated variables into clusters ? How many clusters do you see ? Can you link them with the 3 expressions of tolerance mentioned in Table 1 ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a pearson correlation test between 'q1' and 'q3'. Is the test significant? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performa a pearson correlation test between 'q1' and 'q8' Is the test significant ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the above correlation analysis would you remove any question from the survey ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reliability test with Cronbach's alpha\n",
    "\n",
    "\n",
    "The next step is reliability analysis through Cronbach's Alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does Cronbach's Alpha measures?**\n",
    "\n",
    "Using scales to measure constructs is widespread in the social sciences and beyond.  To support the application of these scales, researchers and practitioners need to show evidence of appropriate reliability.  Many different types of reliability exist, but internal consistency reliability is perhaps the most popular.  Even yet, many metrics exist to provide evidence of internal consistency reliability, but Cronbach’s alpha is perhaps the most popular of these.  For this reason, I provide a guide below of how to calculate Cronbach’s alpha in Python.\n",
    "\n",
    "Whenever we use multiple items/questions to measure a **latent (non-observable) construct**, we call this set of items/questions a **scale**. For example, in this usecase, we want to find out our students' attitudes towards tolerance. Since we can't measure attitudes directly simply asking them \"how tolerance you are?\" due to different definition and understanding of tolerance, we should create a **construct** that attempts to measure same things. \n",
    "\n",
    "For our usecase, we don't want to deal with each of these 8 variables separately. Rather we want to develop composite measures that combine these variables. Let's start by developing three composite measures as indicated in [1] theoretical framework.\n",
    "\n",
    "\n",
    "Each construct (of tolerance) has three (or two) variables. We need to determine if these three variables are internally consistent. This is basically a question of reliability. A commonly used measure of reliability is Cronbach's Alpha. \n",
    "\n",
    "\n",
    "To make sure we did a good job at constructing these scales, we need to use some quality measures. In general, we want to test a scale for validity and reliability. A scale is valid if it actually measures the construct it’s supposed to measure. Reliability is concerned with the ability of an instrument to measure consistently. An instrument cannot be valid unless it is reliable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does Cronbach's Alpha help?**\n",
    "\n",
    "\n",
    "Cronbach's Alpha tells us how **internally consistent** is our scale. **It is the degree to which all observed variables in a scale measure the same construct**. If q1, q2, q3 all contribute to measuring the same thing **(acceptance)** and if these items/questions are correlated we would expect Cronbach alpha to be high. Items that don't really seem to correlate would then be with low Cronbach's Alpha. It helps to answer the following question:\n",
    "\n",
    "> _Do the items I picked to measure a construct line up?_ For instance, how well questions q1, q2 and q3 in the survey measure the **acceptance** construct of tolerance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to interpret Cronbach's Alpha?**\n",
    "\n",
    "Cronbach's Alpha statistic (α) normally varies from 0 and 1.  Low values indicate low consistency and high values indicate high consistency.  Alpha increases as the number of items increases and as the correlation between items increases.  One rule of thumb that is often used is that an Alpha of .70 or higher is necessary to indicate reliability although some feel that a higher value is required. See the table below:\n",
    "\n",
    "\n",
    "| Cronbach’s   Alpha | Internal consistency | \n",
    "|:------------------:|:--------------------:|\n",
    "| 0.9 ≤ α            | Excellent            |\n",
    "| 0.8 ≤ α   < 0.9    | Good                 |\n",
    "| 0.7 ≤ α   < 0.8    | Acceptable           |\n",
    "| 0.6 ≤ α   < 0.7    | Questionable         |\n",
    "| 0.5 ≤ α   < 0.6    | Poor                 |\n",
    "| α < 0.5            | Unacceptable         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to calculate Cronbach's Alpha in python?**\n",
    "\n",
    "To calculate Cronbach’s Alpha in python for the survey responses, we will use the `cronbach_alpha()` function from the [pingouin](https://pingouin-stats.org/) library.\n",
    "\n",
    "However, there is also another approach to calculating Cronbach alpha that is much better suited for data science. As you notice, none of the common data science libraries like NumPy, Pandas, or Sklearn feature Cronbach alpha measures. This [article](https://towardsdatascience.com/cronbachs-alpha-theory-and-application-in-python-d2915dd63586) will show you exactly how to create your own function. However, there is a reason I haven’t told you yet. The approach you will learn today is much more intuitive and easier to understand.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cronbach's Alpha - For all the Items (Entire DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the installation instructions here:\n",
    "# https://pingouin-stats.org/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to read the [official documentation](\n",
    "https://pingouin-stats.org/generated/pingouin.cronbach_alpha.html) and figure out how this function works: \n",
    "\n",
    "Tip: to calculate a Cronbach’s alpha, our syntax is very simple.  We just need to type in: `pg.cronbach_alpha(data= #name) `.  Then we enter the `#name` of our data, followed by closing our parenthesis. Then press enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.cronbach_alpha(data = df_tutorial_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the default confidence interval from 95% to 90%. What does it mean?\n",
    "# Hint: we can specify a different confidence level using the ci argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The previous exercice calculated the Cronbach’s alpha of all the 8 variables in the dataset together. This can be helpful if your dataset only includes a single construct, but according to our theoretical model [1], we may have 3 expressions of tolerance or 3 constructs of tolerance (you will see in next tutorial, how to compute the factors) and we want to calculate a separate Cronbach’s alpha for each of them.**\n",
    "\n",
    "**So what do we do next?**\n",
    "\n",
    "Well, we can add a little bit of code that can separate our constructs in the dataset.  To do this, we must first know which variables are included for which construct.  For instance, we must know that **q1, q2, and q3 are grouped in Acceptance_Construct, whereas variables q4, q5, must be in Respect_Construct and the remaining q6, q7, q8 are in Appreciation_Construct**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cronbach's Alpha for 3 Constructs: Acceptance, Respect and Appreciation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To separete our variables in three constructs we need to add some additional code as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame named Acceptance_Construct containing q1, q2,q3\n",
    "\n",
    "# calculate the cronbach alpha for this construct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cronbach alpha for the two other Constructs - 'Respect' and 'Appreciation'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So... what do our findings tell us? Is the questionnaire reliable ? Are the items in each of the 3 constructs  reliable ? If so, why ? If not, why ? Record your observations for the reliability analysis of the above questionnaire** "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "Tutorial 1: Analysing survey Data (Tolerance construct)",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
